{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SagarBDollin_RNN+CNN",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrtDqvjajuyn",
        "outputId": "f68c7019-56bf-4bed-d653-00bf41308c38"
      },
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00380/YouTube-Spam-Collection-v1.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-02 08:31:22--  https://archive.ics.uci.edu/ml/machine-learning-databases/00380/YouTube-Spam-Collection-v1.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 163567 (160K) [application/x-httpd-php]\n",
            "Saving to: ‘YouTube-Spam-Collection-v1.zip’\n",
            "\n",
            "YouTube-Spam-Collec 100%[===================>] 159.73K   412KB/s    in 0.4s    \n",
            "\n",
            "2021-12-02 08:31:23 (412 KB/s) - ‘YouTube-Spam-Collection-v1.zip’ saved [163567/163567]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQ-VwrV3kGpr"
      },
      "source": [
        "import os\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import torch\n",
        "import torch.optim as O\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torchtext.utils import extract_archive\n",
        "from torchtext.legacy.data import Field, TabularDataset, BucketIterator\n",
        "import spacy\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "import logging\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "from pdb import set_trace\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CE7Hs7mDkQAe"
      },
      "source": [
        "def get_device(gpu_no):\n",
        "  if torch.cuda.is_available():\n",
        "   return torch.device('cuda',gpu_no)\n",
        "  else:\n",
        "    return torch.device('cpu')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yQyQw1FkTN8",
        "outputId": "729d0714-4c76-42b8-e1e9-0faebd885e73"
      },
      "source": [
        "device = get_device(0)\n",
        "print(device)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKW0WIO8kwF0"
      },
      "source": [
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dm-zdfDCky70",
        "outputId": "5744682c-120d-45f1-be4a-7e90eb6cf348"
      },
      "source": [
        "#https://pytorch.org/tutorials/beginner/torchtext_translation_tutorial.html\n",
        "\n",
        "data_file = \"YouTube-Spam-Collection-v1.zip\"\n",
        "paths = extract_archive(data_file,\"data\")\n",
        "\n",
        "for file in paths:\n",
        "  if re.search('__MACOS',file):\n",
        "    paths.remove(file)\n",
        "paths"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data/Youtube01-Psy.csv',\n",
              " 'data/Youtube02-KatyPerry.csv',\n",
              " 'data/Youtube03-LMFAO.csv',\n",
              " 'data/Youtube04-Eminem.csv',\n",
              " 'data/Youtube05-Shakira.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlBNCiZ5P7zz"
      },
      "source": [
        "# Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXRAaHUkqpPa"
      },
      "source": [
        "class Dataset():\n",
        "  def __init__(self,paths):\n",
        "    paths.sort()\n",
        "    self.df,self.train_df,self.val_df = self.create_df(paths)\n",
        "    \n",
        "    self.CONTENT = Field(sequential=True, tokenize=self.tokenizer, lower=True)\n",
        "    self.CLASS = Field(dtype = torch.float,batch_first=True)\n",
        "\n",
        "    self.load_dataset()\n",
        "    \n",
        "    # Create embeddings\n",
        "    self.create_embeddings()\n",
        "    \n",
        "    self.divide_batch()\n",
        "  def tokenizer(self,sent):\n",
        "    return [token.text for token in spacy_en.tokenizer(sent) ]\n",
        "\n",
        "  def create_embeddings(self):\n",
        "    self.CONTENT.build_vocab(self.train_ds, vectors='glove.twitter.27B.100d')\n",
        "    self.CLASS.build_vocab(self.train_ds)\n",
        "  \n",
        "  def create_df(self,paths):\n",
        "    dfs = list()\n",
        "    for i in range(len(paths)):\n",
        "      dfs.append(pd.read_csv(paths[i], header=0))\n",
        "    df = pd.concat(dfs)\n",
        "    df.drop(list(df.columns[0:3]),axis='columns',inplace=True)\n",
        "    train_df, val_df = train_test_split(df, shuffle=True, test_size=0.2, random_state=42)\n",
        "    return df,train_df,val_df\n",
        "  \n",
        "  def load_dataset(self):\n",
        "      self.train_df.to_csv('train_df.tsv',sep='\\t',index=False)\n",
        "      self.val_df.to_csv('val_df.tsv',sep='\\t',index=False)\n",
        "      fields = [\n",
        "    ('CONTENT', self.CONTENT),\n",
        "    ('CLASS', self.CLASS)\n",
        "      ]\n",
        "      self.train_ds, self.valid_ds = TabularDataset.splits(\n",
        "      path = '',\n",
        "      train = 'train_df.tsv',\n",
        "      validation = 'val_df.tsv',\n",
        "      format = 'tsv',\n",
        "      fields = fields,\n",
        "      skip_header = True\n",
        "    )\n",
        "\n",
        "  def divide_batch(self):    \n",
        "      self.train_iter, self.val_iter = BucketIterator.splits(\n",
        "    (self.train_ds, self.valid_ds),\n",
        "    sort = False,\n",
        "    batch_size = 32,\n",
        "    device = get_device(0)\n",
        "  )"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eg3R3BaqO4oI"
      },
      "source": [
        "# Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5B5KOP3oOjIM"
      },
      "source": [
        "![model_architecture.jpg](https://drive.google.com/uc?id=1pG1nHTkWGueGSg6YMvNDjl_RphUqHPpm)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro97MnWwZW3r"
      },
      "source": [
        "# https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(RNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "    self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
        "  def forward(self, input, hidden):\n",
        "    combined = torch.cat((input, hidden), -1)\n",
        "    hidden = self.i2h(combined)\n",
        "    output = self.i2o(combined)\n",
        "    # output = self.softmax(output)\n",
        "    # output = torch.argmax(output, dim=1)\n",
        "    return output, hidden\n",
        "# https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self,input_size,output_size):\n",
        "    super(CNN,self).__init__()\n",
        "    self.conv1 = nn.Conv1d(1, 6, 5)\n",
        "    self.pool = nn.MaxPool1d(2)\n",
        "    self.conv2 = nn.Conv1d(6, 6, 5)\n",
        "    self.fc1 = nn.Linear(132, 64)\n",
        "    self.fc2 = nn.Linear(64, 16)\n",
        "    self.fc3 = nn.Linear(16, output_size)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    x = self.softmax(x)\n",
        "    return x  "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE_wCYSvwdnf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac2ea7c1-6593-4b5b-918d-b4352acb140c"
      },
      "source": [
        "dataset = Dataset(paths)\n",
        "params = {\n",
        "    'target_size':2,\n",
        "    'input_size':100,\n",
        "    'epochs':40,\n",
        "    'lr':1e-4,\n",
        "    'results_dir':'results_dir'\n",
        "    }\n",
        "embeddings = {\n",
        "    'CONTENT_emb':dataset.CONTENT.vocab.vectors.to(device),\n",
        "    }\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.twitter.27B.zip: 1.52GB [06:58, 3.63MB/s]                            \n",
            "100%|█████████▉| 1193513/1193514 [01:03<00:00, 18699.94it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWewdcp372vb"
      },
      "source": [
        "#Utilities\n",
        "def labels_gold(gold):\n",
        "  labels = {0:2}\n",
        "  i=1\n",
        "  while(len(labels.keys())<2):\n",
        "    if gold[i] != labels[0]: \n",
        "        labels[1] = gold[i]\n",
        "        break\n",
        "    i+=1\n",
        "  return labels\n",
        "\n",
        "# https://stackoverflow.com/questions/45384684/replace-all-nonzero-values-by-zero-and-all-zero-values-by-a-specific-value\n",
        "def normalize_gold(gold):\n",
        "  labels = labels_gold(gold)\n",
        "  res = gold.clone()\n",
        "  res[gold == labels[1]] = 1.\n",
        "  \n",
        "  res[gold == labels[0]] = 0.\n",
        "  return res.long().squeeze()\n",
        "\n",
        "def makedirs(name):\n",
        "\t\"\"\"helper function for python 2 and 3 to call os.makedirs()\n",
        "\t\tavoiding an error if the directory to be created already exists\"\"\"\n",
        "\n",
        "\timport os, errno\n",
        "\n",
        "\ttry:\n",
        "\t\tos.makedirs(name)\n",
        "\texcept OSError as ex:\n",
        "\t\tif ex.errno == errno.EEXIST and os.path.isdir(name):\n",
        "\t\t\t# ignore existing directory\n",
        "\t\t\tpass\n",
        "\t\telse:\n",
        "\t\t\t# a different error happened\n",
        "\t\t\traise\n",
        "def get_logger(params, phase):\n",
        "\tlogging.basicConfig(level=logging.INFO, \n",
        "\t\t\t\t\t\t\t\t\t\t\t\tfilename = \"{}/{}/{}/{}.log\".format(params['results_dir'], 'rnn+cnn', 'dataset', phase),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tformat = '%(asctime)s - %(message)s', \n",
        "\t\t\t\t\t\t\t\t\t\t\t\tdatefmt='%d-%b-%y %H:%M:%S')\n",
        "\treturn logging.getLogger(phase)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8uvxGBpa8xs"
      },
      "source": [
        "#Training\n",
        "class Train():\n",
        "  def __init__(self, params, embeddings):\n",
        "    emb_size = params['input_size']\n",
        "    target_size = params['target_size']\n",
        "    self.epochs = params['epochs']\n",
        "    self.results_dir = params['results_dir']\n",
        "    self.embeddings = embeddings\n",
        "    \n",
        "    self.rnn = RNN(input_size=emb_size,hidden_size=emb_size,output_size=emb_size)\n",
        "    self.cnn = CNN(emb_size,target_size)\n",
        "    self.rnn.to(device)\n",
        "    self.cnn.to(device)\n",
        "    self.dataset = dataset\n",
        "    self.opt = O.Adam((list(self.rnn.parameters())+list(self.cnn.parameters())), lr = params['lr'])\n",
        "    self.scheduler = ReduceLROnPlateau(optimizer=self.opt, mode='min',factor=1e-1,patience=5)\n",
        "    self.best_val_acc = None\n",
        "    self.logger = get_logger(params,'train')\n",
        "  \n",
        "  def train(self):\n",
        "    self.rnn.train(); self.dataset.train_iter.init_epoch()\n",
        "    n_correct, n_total, n_loss = 0, 0, 0\n",
        "    criterion = nn.CrossEntropyLoss(reduction = 'sum')\n",
        "    for batch in self.dataset.train_iter:\n",
        "      batch.CONTENT.to(device)\n",
        "      batch.CLASS.to(device)\n",
        "      self.opt.zero_grad()\n",
        "      # batch.CONTENT = batch.CONTENT.reshape((batch.CONTENT.shape[1],batch.CONTENT.shape[0]))\n",
        "      batch_lines = self.embeddings['CONTENT_emb'][batch.CONTENT]\n",
        "      hidden = torch.zeros(batch_lines.shape[1:]).to(device)\n",
        "      outputs = torch.zeros(batch_lines.shape[1:]).to(device)\n",
        "      \n",
        "      for batch_word in batch_lines:\n",
        "        out, hidden = self.rnn(batch_word,hidden)\n",
        "        outputs += out\n",
        "      outputs = outputs.reshape(batch.batch_size,1,100)\n",
        "      output = self.cnn(outputs)  \n",
        "      batch.CLASS = normalize_gold(batch.CLASS)\n",
        "      # print(output.shape,batch.CLASS.shape)\n",
        "      loss = criterion(output, batch.CLASS)\n",
        "      n_correct += (torch.max(output, 1)[1].view(batch.CLASS.size()) == batch.CLASS).sum().item()\n",
        "      n_total += batch.batch_size\n",
        "      n_loss += loss.item()\n",
        "\n",
        "      loss.backward(); self.opt.step()\n",
        "\n",
        "    train_loss = n_loss/n_total\n",
        "    train_acc = 100. * n_correct/n_total\n",
        "    return train_loss,train_acc\n",
        "  \n",
        "  def validate(self):\n",
        "    self.rnn.eval(); self.cnn.eval(); self.dataset.val_iter.init_epoch()\n",
        "    n_correct, n_total, n_loss = 0, 0, 0\n",
        "    criterion = nn.CrossEntropyLoss(reduction = 'sum')\n",
        "    with torch.no_grad():\n",
        "      for batch_idx, batch in enumerate(self.dataset.val_iter):\n",
        "        batch.CONTENT.to(device)\n",
        "        batch.CLASS.to(device)\n",
        "        batch_lines = self.embeddings['CONTENT_emb'][batch.CONTENT]\n",
        "        hidden = torch.zeros(batch_lines.shape[1:]).to(device)\n",
        "        outputs = torch.zeros(batch_lines.shape[1:]).to(device)\n",
        "        \n",
        "        for batch_word in batch_lines:\n",
        "          out, hidden = self.rnn(batch_word,hidden)\n",
        "          outputs += out\n",
        "        outputs = outputs.reshape(batch.batch_size,1,100)\n",
        "        output = self.cnn(outputs)  \n",
        "        batch.CLASS = normalize_gold(batch.CLASS)\n",
        "        loss = criterion(output, batch.CLASS)\n",
        "        n_correct += (torch.max(output, 1)[1].view(batch.CLASS.size()) == batch.CLASS).sum().item()\n",
        "        n_total += batch.batch_size\n",
        "        n_loss += loss.item()\n",
        "      val_loss = n_loss/n_total\n",
        "      val_acc = 100. * n_correct/n_total\n",
        "    return val_loss, val_acc\n",
        "  \n",
        "  def execute(self):\n",
        "    print(\" [*] Training starts!\")\n",
        "    print('-' * 99)\n",
        "    for epoch in range(1, self.epochs+1):\n",
        "      start = time.time()\n",
        "      train_loss, train_acc = self.train()\n",
        "      val_loss, val_acc = self.validate()\n",
        "      self.scheduler.step(train_loss)\n",
        "      took = time.time()-start\n",
        "      \n",
        "      self.result_checkpoint(epoch, train_loss, val_loss, train_acc, val_acc, took)\n",
        "      print('| Epoch {:3d} | train loss {:5.2f} | train acc {:5.2f} | val loss {:5.2f} | val acc {:5.2f} | time: {:5.2f}s |'.format(\n",
        "        epoch, train_loss, train_acc, val_loss, val_acc, took))\n",
        "    self.finish()\n",
        "  \n",
        "  def result_checkpoint(self, epoch, train_loss, val_loss, train_acc, val_acc, took):\n",
        "    if self.best_val_acc is None or val_acc > self.best_val_acc:\n",
        "      self.best_val_acc = val_acc\n",
        "      makedirs('{}/{}/{}'.format(self.results_dir, 'model', 'dataset'))\n",
        "      torch.save({\n",
        "        'accuracy': self.best_val_acc,\n",
        "        # 'options': self.model_options,\n",
        "        'model_dict': self.rnn.state_dict(),\n",
        "      }, '{}/{}/{}/best-{}-{}-params.pth'.format(self.results_dir, 'model', 'dataset','rnn', 'dataset'))\n",
        "    torch.save({\n",
        "        'accuracy': self.best_val_acc,\n",
        "        # 'options': self.model_options,\n",
        "        'model_dict': self.cnn.state_dict(),\n",
        "      }, '{}/{}/{}/best-{}-{}-params.pth'.format(self.results_dir, 'model', 'dataset','cnn', 'dataset'))\n",
        "    self.logger.info('| Epoch {:3d} | train loss {:5.2f} | train acc {:5.2f} | val loss {:5.2f} | val acc {:5.2f} | time: {:5.2f}s |'\n",
        "        .format(epoch, train_loss, train_acc, val_loss, val_acc, took))\n",
        "  \n",
        "  def finish(self):\n",
        "    self.logger.info(\"[*] Training finished!\\n\\n\")\n",
        "    print('-' * 99)\n",
        "    print(\" [*] Training finished!\")\n",
        "    print(\" [*] Please find the saved model and training log in results_dir\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3rSfrfHIWEA",
        "outputId": "af335ef9-2529-4e04-8b29-8d1d28822637"
      },
      "source": [
        "train = Train(params,embeddings)\n",
        "train.execute()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [*] Training starts!\n",
            "---------------------------------------------------------------------------------------------------\n",
            "| Epoch   1 | train loss  0.68 | train acc 58.44 | val loss  0.67 | val acc 57.14 | time:  2.68s |\n",
            "| Epoch   2 | train loss  0.65 | train acc 63.75 | val loss  0.65 | val acc 57.65 | time:  2.23s |\n",
            "| Epoch   3 | train loss  0.62 | train acc 71.42 | val loss  0.63 | val acc 61.99 | time:  2.30s |\n",
            "| Epoch   4 | train loss  0.56 | train acc 81.52 | val loss  0.52 | val acc 86.22 | time:  2.35s |\n",
            "| Epoch   5 | train loss  0.48 | train acc 85.55 | val loss  0.46 | val acc 87.24 | time:  2.34s |\n",
            "| Epoch   6 | train loss  0.45 | train acc 86.57 | val loss  0.46 | val acc 85.71 | time:  2.33s |\n",
            "| Epoch   7 | train loss  0.44 | train acc 86.76 | val loss  0.47 | val acc 84.95 | time:  2.33s |\n",
            "| Epoch   8 | train loss  0.43 | train acc 87.92 | val loss  0.44 | val acc 86.99 | time:  2.37s |\n",
            "| Epoch   9 | train loss  0.44 | train acc 87.15 | val loss  0.45 | val acc 86.22 | time:  2.28s |\n",
            "| Epoch  10 | train loss  0.44 | train acc 87.60 | val loss  0.43 | val acc 88.27 | time:  2.35s |\n",
            "| Epoch  11 | train loss  0.44 | train acc 86.89 | val loss  0.44 | val acc 86.99 | time:  2.26s |\n",
            "| Epoch  12 | train loss  0.43 | train acc 88.24 | val loss  0.43 | val acc 87.50 | time:  2.29s |\n",
            "| Epoch  13 | train loss  0.43 | train acc 87.66 | val loss  0.44 | val acc 86.73 | time:  2.27s |\n",
            "| Epoch  14 | train loss  0.43 | train acc 88.24 | val loss  0.43 | val acc 88.52 | time:  2.25s |\n",
            "| Epoch  15 | train loss  0.42 | train acc 88.68 | val loss  0.44 | val acc 86.73 | time:  2.26s |\n",
            "| Epoch  16 | train loss  0.42 | train acc 89.00 | val loss  0.43 | val acc 87.50 | time:  2.30s |\n",
            "| Epoch  17 | train loss  0.42 | train acc 89.07 | val loss  0.44 | val acc 87.24 | time:  2.33s |\n",
            "| Epoch  18 | train loss  0.42 | train acc 88.68 | val loss  0.43 | val acc 88.01 | time:  2.25s |\n",
            "| Epoch  19 | train loss  0.42 | train acc 89.32 | val loss  0.43 | val acc 88.27 | time:  2.23s |\n",
            "| Epoch  20 | train loss  0.42 | train acc 88.75 | val loss  0.44 | val acc 87.76 | time:  2.24s |\n",
            "| Epoch  21 | train loss  0.42 | train acc 88.94 | val loss  0.43 | val acc 88.27 | time:  2.32s |\n",
            "| Epoch  22 | train loss  0.42 | train acc 89.51 | val loss  0.43 | val acc 87.50 | time:  2.26s |\n",
            "| Epoch  23 | train loss  0.41 | train acc 89.45 | val loss  0.43 | val acc 87.24 | time:  2.36s |\n",
            "| Epoch  24 | train loss  0.41 | train acc 90.28 | val loss  0.43 | val acc 87.76 | time:  2.25s |\n",
            "| Epoch  25 | train loss  0.41 | train acc 89.90 | val loss  0.43 | val acc 87.76 | time:  2.31s |\n",
            "| Epoch  26 | train loss  0.41 | train acc 89.96 | val loss  0.43 | val acc 89.03 | time:  2.36s |\n",
            "| Epoch  27 | train loss  0.41 | train acc 90.28 | val loss  0.42 | val acc 88.27 | time:  2.31s |\n",
            "| Epoch  28 | train loss  0.43 | train acc 88.30 | val loss  0.43 | val acc 87.76 | time:  2.33s |\n",
            "| Epoch  29 | train loss  0.42 | train acc 89.51 | val loss  0.43 | val acc 88.01 | time:  2.21s |\n",
            "| Epoch  30 | train loss  0.41 | train acc 89.77 | val loss  0.43 | val acc 88.27 | time:  2.32s |\n",
            "| Epoch  31 | train loss  0.41 | train acc 89.64 | val loss  0.43 | val acc 88.52 | time:  2.30s |\n",
            "| Epoch  32 | train loss  0.41 | train acc 90.86 | val loss  0.43 | val acc 88.01 | time:  2.28s |\n",
            "| Epoch  33 | train loss  0.41 | train acc 89.58 | val loss  0.43 | val acc 87.50 | time:  2.30s |\n",
            "| Epoch  34 | train loss  0.41 | train acc 89.39 | val loss  0.43 | val acc 88.27 | time:  2.26s |\n",
            "| Epoch  35 | train loss  0.40 | train acc 90.73 | val loss  0.43 | val acc 88.27 | time:  2.27s |\n",
            "| Epoch  36 | train loss  0.41 | train acc 90.22 | val loss  0.42 | val acc 88.78 | time:  2.37s |\n",
            "| Epoch  37 | train loss  0.41 | train acc 90.54 | val loss  0.43 | val acc 88.27 | time:  2.37s |\n",
            "| Epoch  38 | train loss  0.41 | train acc 90.47 | val loss  0.44 | val acc 87.50 | time:  2.30s |\n",
            "| Epoch  39 | train loss  0.41 | train acc 89.83 | val loss  0.43 | val acc 88.52 | time:  2.35s |\n",
            "| Epoch  40 | train loss  0.42 | train acc 89.51 | val loss  0.44 | val acc 86.48 | time:  2.33s |\n",
            "---------------------------------------------------------------------------------------------------\n",
            " [*] Training finished!\n",
            " [*] Please find the saved model and training log in results_dir\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcozizmMihra",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e490b3a-7908-4eac-dab8-2b155e58fee1"
      },
      "source": [
        "#Zipping the model that gave best val accuracy. \n",
        "!zip -r results_dir.zip results_dir"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: results_dir/ (stored 0%)\n",
            "  adding: results_dir/model/ (stored 0%)\n",
            "  adding: results_dir/model/dataset/ (stored 0%)\n",
            "  adding: results_dir/model/dataset/best-cnn-dataset-params.pth (deflated 11%)\n",
            "  adding: results_dir/model/dataset/best-rnn-dataset-params.pth (deflated 8%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcIoVGq-oRrY"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    }
  ]
}